# ğŸ£ Mini GCP (Local Data Pipeline)

This project simulates a **modern data pipeline** architecture, entirely **locally** and **without requiring Google Cloud or paid services**. It follows a modular design to extract, transform, load, validate, and analyze synthetic sales data using Python, Apache Beam, DuckDB, and PostgreSQL (optional).

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ data/             # Data storage layer (raw, processed, validated, warehouse)
â”œâ”€â”€ extract/          # Data extraction logic
â”œâ”€â”€ transform/        # Data transformation using Apache Beam
â”œâ”€â”€ load/             # Load cleaned data into DuckDB
â”œâ”€â”€ validate/         # Schema and quality validation
â”œâ”€â”€ export/           # Optional: export to PostgreSQL
â”œâ”€â”€ functions/        # Trigger logic (e.g., on new file)
â”œâ”€â”€ scripts/          # Automation scripts
â”œâ”€â”€ requirements.txt  # Python dependencies
â””â”€â”€ README.md         # You are here!
```

---